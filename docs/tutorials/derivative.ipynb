{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ec0497",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    import smolgp\n",
    "except ImportError:\n",
    "    %pip install -q smolgp\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31275a3",
   "metadata": {},
   "source": [
    "(derivative)="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad0f16",
   "metadata": {},
   "source": [
    "# Derivative Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f34100",
   "metadata": {},
   "source": [
    "In `tinygp`, one can define a custom covariance function with the appropriate derivatives to make the resulting GP be of the derivative of the process. Similarly, one can construct a kernel from a linear combination of a kernel with its derivative(s). See [this `tinygp` tutorial](https://tinygp.readthedocs.io/en/stable/tutorials/derivative.html) for morme details.\n",
    "\n",
    "In `smolgp`, observing the derivative of a process is conceptually easier. Recall the observation matrix e.g. for the SHO is `H = [1, 0]`, which picks out the latent process in the first position of the state vector. If we want the derivative, we would simply instead use `H = [0, 1]` and so on for higher dimensional kernels (e.g., the MatÃ©rn-5/2 is defined by a 3rd order SDE and so one can go up to the second derivative with `H = [0, 0, 1]`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5293611",
   "metadata": {},
   "source": [
    "To do this, define a `Wrapper` kernel that mirrors the kernel of interest but overloads the `observation_matrix`. E.g. for the SHO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74f3cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "from tinygp.helpers import JAXArray\n",
    "from smolgp.kernels import Wrapper\n",
    "\n",
    "class SHODerivative(Wrapper):\n",
    "    \"\"\"A GP for the first derivative of a SHO\"\"\"\n",
    "\n",
    "    omega: JAXArray | float\n",
    "    quality: JAXArray | float\n",
    "    sigma: JAXArray | float = eqx.field(default_factory=lambda: jnp.ones(()))\n",
    "\n",
    "    def __init__(self, omega: JAXArray | float, \n",
    "             quality: JAXArray | float, \n",
    "             sigma: JAXArray | float = 1.0,\n",
    "             name: str='SHODerivative'):\n",
    "        self.omega = omega\n",
    "        self.quality = quality\n",
    "        self.sigma = sigma\n",
    "        self.name = name\n",
    "        self.kernel = smolgp.kernels.SHO(omega=omega, quality=quality, sigma=sigma)\n",
    "\n",
    "    def observation_matrix(self, X: JAXArray) -> JAXArray:\n",
    "        \"\"\"The observation model H for the derivative of a SHO process\"\"\"\n",
    "        del X\n",
    "        return jnp.array([[0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224c0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = SHODerivative(omega=2*jnp.pi /50, quality=5.0, sigma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31661445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smolgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
